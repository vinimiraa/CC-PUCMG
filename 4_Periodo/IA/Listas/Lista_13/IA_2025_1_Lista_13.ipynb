{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Inteligência Artificial**\n",
        "\n",
        "**812839 - Vinícius Miranda de Araújo**\n",
        "\n",
        "**Lista de Exercícios 13**\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "mskxuCDraau6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questão 1"
      ],
      "metadata": {
        "id": "cMw0Qa9vpMMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalando  e importando bibliotecas"
      ],
      "metadata": {
        "id": "qdyTPiIdGH6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-multilearn\n",
        "!pip install scikit-learn\n",
        "!pip install nltk\n",
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYLpAUhbGGz9",
        "outputId": "2960382f-e717-4894-cefc-ca743c2c5641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, hamming_loss, classification_report\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import vstack"
      ],
      "metadata": {
        "id": "0sEKaPMUGQrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando a base de dados"
      ],
      "metadata": {
        "id": "tKsGPyx5GWcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Carregar o dataset\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "test_labels = pd.read_csv('test_labels.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIE4m3XeGZcy",
        "outputId": "d1b4bc38-7edd-4e05-9417-032f9bbd17e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando\n",
        "print(\"Dados de treino:\\n\")\n",
        "print(train.head())\n",
        "print(train.shape)\n",
        "\n",
        "print(\"\\nDados de teste:\\n\")\n",
        "print(test.head())\n",
        "print(test.shape)\n",
        "\n",
        "print(\"\\nLabels de teste:\\n\")\n",
        "print(test_labels.head())\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxH5r2eQQ1XN",
        "outputId": "2aad3cf0-565c-4405-a39e-2f7172018fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados de treino:\n",
            "\n",
            "                 id                                       comment_text  toxic  \\\n",
            "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
            "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
            "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
            "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
            "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
            "\n",
            "   severe_toxic  obscene  threat  insult  identity_hate  \n",
            "0             0        0       0       0              0  \n",
            "1             0        0       0       0              0  \n",
            "2             0        0       0       0              0  \n",
            "3             0        0       0       0              0  \n",
            "4             0        0       0       0              0  \n",
            "(159571, 8)\n",
            "\n",
            "Dados de teste:\n",
            "\n",
            "                 id                                       comment_text\n",
            "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
            "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
            "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
            "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
            "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
            "(153164, 2)\n",
            "\n",
            "Labels de teste:\n",
            "\n",
            "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
            "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
            "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
            "2  00013b17ad220c46     -1            -1       -1      -1      -1   \n",
            "3  00017563c3f7919a     -1            -1       -1      -1      -1   \n",
            "4  00017695ad8997eb     -1            -1       -1      -1      -1   \n",
            "\n",
            "   identity_hate  \n",
            "0             -1  \n",
            "1             -1  \n",
            "2             -1  \n",
            "3             -1  \n",
            "4             -1  \n",
            "(153164, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pré-processamento do texto"
      ],
      "metadata": {
        "id": "cxYFRtKjGlHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels de classificação\n",
        "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ],
      "metadata": {
        "id": "cERWW8bqeYGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento dos textos\n",
        "def preprocess(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove pontuação\n",
        "    text = re.sub(r'\\d+', '', text)      # Remove números\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Aplicar pré-processamento\n",
        "train['comment_text'] = train['comment_text'].apply(preprocess)\n",
        "test['comment_text'] = test['comment_text'].apply(preprocess)\n",
        "\n",
        "# Vetorização TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=10000)\n",
        "X_train = tfidf.fit_transform(train['comment_text'])\n",
        "X_test = tfidf.transform(test['comment_text'])\n",
        "\n",
        "y_train = train[labels].values\n",
        "y_test_labels = test_labels[labels].values\n",
        "\n",
        "# Filtrar apenas os exemplos válidos no conjunto de teste\n",
        "# (Aqueles que não têm -1 em nenhuma das labels)\n",
        "valid_rows = ~(y_test_labels == -1).any(axis=1)\n",
        "\n",
        "X_test_valid = X_test[valid_rows]\n",
        "y_test_valid = y_test_labels[valid_rows]"
      ],
      "metadata": {
        "id": "e57-k-apGqhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo 1: Sem balanceamento"
      ],
      "metadata": {
        "id": "Sswz_omtPpog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_base = BinaryRelevance(classifier=LogisticRegression(max_iter=1000))\n",
        "model_base.fit(X_train, y_train)\n",
        "y_pred_base = model_base.predict(X_test_valid)"
      ],
      "metadata": {
        "id": "yu0e_5ICPvf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Avaliação do Modelo 1"
      ],
      "metadata": {
        "id": "DbdkfrGgQKx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Avaliação Modelo Base ===\")\n",
        "print(\"Hamming Loss:\", hamming_loss(y_test_valid, y_pred_base))\n",
        "print(\"F1 Micro:\", f1_score(y_test_valid, y_pred_base, average='micro'))\n",
        "print(\"F1 Macro:\", f1_score(y_test_valid, y_pred_base, average='macro'))\n",
        "print(\"Subset Accuracy:\", accuracy_score(y_test_valid, y_pred_base))\n",
        "print(classification_report(y_test_valid, y_pred_base, target_names=labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRRWu0QpQNns",
        "outputId": "f8ef2d7f-de39-4a27-9249-2590483b4256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Avaliação Modelo Base ===\n",
            "Hamming Loss: 0.025782300165681952\n",
            "F1 Micro: 0.6370071520264075\n",
            "F1 Macro: 0.4871900326087752\n",
            "Subset Accuracy: 0.8951201975679139\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.65      0.71      0.68      6090\n",
            " severe_toxic       0.41      0.32      0.36       367\n",
            "      obscene       0.75      0.61      0.68      3691\n",
            "       threat       0.45      0.18      0.26       211\n",
            "       insult       0.73      0.52      0.61      3427\n",
            "identity_hate       0.62      0.24      0.35       712\n",
            "\n",
            "    micro avg       0.68      0.60      0.64     14498\n",
            "    macro avg       0.60      0.43      0.49     14498\n",
            " weighted avg       0.68      0.60      0.63     14498\n",
            "  samples avg       0.06      0.06      0.06     14498\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo 2: Com Balanceamento (Oversampling)"
      ],
      "metadata": {
        "id": "YaG5VOfzPzD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listas para armazenar dados balanceados temporariamente\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    print(f\"\\nBalanceando label: {label}\")\n",
        "\n",
        "    # Extrai o rótulo específico\n",
        "    y_label = y_train[:, i]\n",
        "\n",
        "    # Inicializa o oversampler\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "    # Aplica o oversampling para essa label específica\n",
        "    X_res, y_res = ros.fit_resample(X_train, y_label)\n",
        "\n",
        "    # Cria o vetor de labels multilabel com zeros\n",
        "    y_res_multi = np.zeros((X_res.shape[0], len(labels)), dtype=int)\n",
        "\n",
        "    # Preenche apenas a coluna da label atual com os valores balanceados\n",
        "    y_res_multi[:, i] = y_res\n",
        "\n",
        "    # Armazena os dados\n",
        "    X_list.append(X_res)\n",
        "    y_list.append(y_res_multi)\n",
        "\n",
        "# Concatena todos os X e Y das labels balanceadas\n",
        "X_bal = vstack(X_list)\n",
        "y_bal = np.vstack(y_list)\n",
        "\n",
        "# Remove duplicatas\n",
        "# df_X = pd.DataFrame(X_bal.toarray())\n",
        "# df_y = pd.DataFrame(y_bal, columns=labels)\n",
        "# df_concat = pd.concat([df_X, df_y], axis=1).drop_duplicates()\n",
        "\n",
        "# Separa novamente X e y\n",
        "# X_bal = csr_matrix(df_concat.iloc[:, :-len(labels)].values)\n",
        "# y_bal = df_concat.iloc[:, -len(labels):].values\n",
        "\n",
        "print(\"\\nShape final após balanceamento e remoção de duplicatas:\", X_bal.shape, y_bal.shape)"
      ],
      "metadata": {
        "id": "9VGQStkHP3te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo balanceado\n",
        "model_balanced = BinaryRelevance(classifier=LogisticRegression(max_iter=1000))\n",
        "model_balanced.fit(X_bal, y_bal)\n",
        "\n",
        "# Predição no conjunto de teste\n",
        "y_pred_balanced = model_balanced.predict(X_test_valid)"
      ],
      "metadata": {
        "id": "UMvigD0Wg0GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Avaliação do Modelo 2"
      ],
      "metadata": {
        "id": "LM_onxWyQVHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Avaliação Modelo Balanceado ===\")\n",
        "print(\"Hamming Loss:\", hamming_loss(y_test_valid, y_pred_balanced))\n",
        "print(\"F1 Micro:\", f1_score(y_test_valid, y_pred_balanced, average='micro'))\n",
        "print(\"F1 Macro:\", f1_score(y_test_valid, y_pred_balanced, average='macro'))\n",
        "print(\"Subset Accuracy:\", accuracy_score(y_test_valid, y_pred_balanced))\n",
        "print(classification_report(y_test_valid, y_pred_balanced, target_names=labels))"
      ],
      "metadata": {
        "id": "A5NphSLoQXCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questão 2"
      ],
      "metadata": {
        "id": "qEKKHvHNd3iI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Questão | Resposta | Justificativa                                                                                                                                                                                                        |\n",
        "| ------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| 1       | A        | A alternativa apresenta corretamente a contrapositiva da sentença \"Se é feriado, os bancos estão fechados\", que é \"Se os bancos não estão fechados, então não é feriado\". Isso utiliza a **regra de contraposição**. |\n",
        "| 4       | E        | Utilizando o **silogismo disjuntivo**, se uma das alternativas \"não chover\" leva Cláudia à praia e \"chover\" leva Fábia ao clube, então, independentemente do tempo, uma das duas irá se divertir.                    |\n",
        "| 5       | A        | Aplicação do **modus ponens**: se as premissas são verdadeiras, então a conclusão também é verdadeira.                                                                                                               |\n",
        "| 7       | A        | Uso do **silogismo hipotético**, onde se $A$ implica $B$ e $B$ implica $C$, então $A$ implica $C$.                                                                                                                   |\n",
        "| 8       | B        | Se não vou à escola, então não há aula. Pela **contraposição**, se há aula, então vou à escola.                                                                                                                      |\n",
        "| 9       | E        | A alternativa correta aplica a regra do **silogismo disjuntivo**, eliminando uma opção para concluir a outra                                                                                                         |\n",
        "| 13      | C        | A alternativa faz uso da **regra de contraposição**, que é logicamente equivalente à condicional.                                                                                                                    |\n",
        "| 16      | E        | Pelo **silogismo disjuntivo**, ao negar uma das alternativas de uma disjunção verdadeira, conclui-se que a outra é verdadeira.                                                                                       |\n",
        "| 17      | B        | Uso da **adição**, que permite que, de uma proposição simples, se derive uma disjunção verdadeira.                                                                                                                   |\n",
        "| 19      | A        | Aplicação direta da regra do **modus ponens**: se $p \\to q$ e $p$ é verdadeiro, então $q$ também é.                                                                                                                  |\n",
        "| 20      | B        | Pela **contraposição**, a condicional \"Se $p$ então $q$\" é equivalente a \"Se não $q$ então não $p$\".                                                                                                                 |\n",
        "| 21      | C        | Aplicação do **silogismo disjuntivo**, descartando uma opção para concluir a outra.                                                                                                                                  |\n",
        "| 23      | B        | Uso da **contraposição**, transformando \"Se $p$ então $q$\" em \"Se não $q$ então não $p$\".                                                                                                                            |\n",
        "| 24      | C        | Uso da **adição**, que permite criar uma disjunção a partir de uma única proposição verdadeira.                                                                                                                      |\n",
        "| 26      | D        | Aplicação da regra de **contraposição**, reconhecendo a equivalência lógica entre uma condicional e sua contrapositiva.                                                                                              |\n",
        "| 27      | C        | Pela **exportação**, uma condicional com conjunção no antecedente pode ser reescrita como uma condicional encadeada.                                                                                                 |\n",
        "| 28      | A        | Aplicação do **modus tollens**: se $p \\to q$ e $~q$, então $~p$.                                                                                                                                                     |\n",
        "| 31      | E        | Não se pode concluir diretamente nada sobre a culpa de Francisco, apenas que não desviou dinheiro. A alternativa E é a que resta como logicamente correta, mas sem informação específica.                            |\n",
        "| 32      | A        | Aplicação da **contraposição**: \"Se Rodrigo mentiu então ele é culpado\" é equivalente a \"Se ele não é culpado então ele não mentiu\".                                                                                 |\n"
      ],
      "metadata": {
        "id": "dPxNCjSQd6Z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questão 3"
      ],
      "metadata": {
        "id": "CCxHp2BhlnHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Aplicação da regra clássica:\n",
        "\n",
        "> “Se a altura $\\ge$ 170 cm, então é alto (1); senão, não é alto (0)”.\n",
        "\n",
        "| Personagem | Altura (cm) | Alto (lógica clássica) |\n",
        "| ---------- | ----------- | ---------------------- |\n",
        "| Ana        | 148         | 0                      |\n",
        "| Bruno      | 165         | 0                      |\n",
        "| Carla      | 172         | 1                      |\n",
        "| Diego      | 180         | 1                      |\n",
        "| Elisa      | 191         | 1                      |"
      ],
      "metadata": {
        "id": "OhlbrzKPlphT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Discutindo se faz sentido dizer que alguém com 169 cm não é nada alto (0) e alguém com 170 cm é totalmente alto (1)?\n",
        "\n",
        "Não faz sentido absoluto. A diferença de 1 cm (169 para 170) não representa uma mudança drástica no conceito de \"alto\". Por isso, a lógica fuzzy é mais adequada, pois permite graus de pertencimento."
      ],
      "metadata": {
        "id": "WResNecRm57W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Propondo uma função de pertinência fuzzy para a categoria \"alto\", que varie de 0 (não é alto) até 1 (muito alto), usando a seguinte lógica linear aproximada:\n",
        "\n",
        "- Se altura < 160 $\\to$ grau = 0\n",
        "    \n",
        "- Se altura > 190 $\\to$ grau = 1\n",
        "    \n",
        "- Se altura entre 160 e 190 $\\to$ $\\text{grau} = \\frac{(\\text{altura} - 160)}{(190 - 160)}$\n",
        "\n",
        "Ou seja:\n",
        "\n",
        "$$\\text{grau} = \\frac{\\text{altura} - 160}{30}$$\n"
      ],
      "metadata": {
        "id": "fWhe_XCAm_54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d) Preenchendo a tabela com os valores fuzzy de \"alto\":\n",
        "\n",
        "| Personagem | Altura (cm) | Grau de \"alto\" (fuzzy)                   |\n",
        "| ---------- | ----------- | ---------------------------------------- |\n",
        "| Ana        | 148         | 0                                        |\n",
        "| Bruno      | 165         | $\\frac{(165-160)}{30}$ = 0,166... ≈ 0,17 |\n",
        "| Carla      | 172         | $\\frac{(172-160)}{30}$ = 0,4             |\n",
        "| Diego      | 180         | $\\frac{(180-160)}{30}$ = 0,666... ≈ 0,67 |\n",
        "| Elisa      | 191         | 1                                        |"
      ],
      "metadata": {
        "id": "eyWzlc-CnlfS"
      }
    }
  ]
}