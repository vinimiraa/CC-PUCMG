{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Inteligência Artificial**\n",
        "\n",
        "**812839 - Vinícius Miranda de Araújo**\n",
        "\n",
        "**Lista de Exercícios 12**\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "k3DQBFKsMv31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkrcT37xMtIO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers, models\n",
        "from keras.utils import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base de Dados"
      ],
      "metadata": {
        "id": "u4d9DqI-M4fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A base de dados \"Cats vs Dogs\" foi retirada do [Kaggle](https://www.kaggle.com/datasets/shaunthesheep/microsoft-catsvsdogs-dataset).\n",
        "\n",
        "- Essa base continha aproximadamente 14.000 imagens de cães e gatos, cada."
      ],
      "metadata": {
        "id": "V9loucZGM7Ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação dos Dados"
      ],
      "metadata": {
        "id": "mvIVBjmfNL2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dowload da Base de Dados"
      ],
      "metadata": {
        "id": "ss2FcJ0WN2Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"shaunthesheep/microsoft-catsvsdogs-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "B-43iAzPN5Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando e Pré-Processando as Imagens"
      ],
      "metadata": {
        "id": "RURluqNVOrA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminhos das imagens\n",
        "dir_cat = \"/kaggle/input/microsoft-catsvsdogs-dataset/versions/1/PetImages/Cat\"\n",
        "dir_dog = \"/kaggle/input/microsoft-catsvsdogs-dataset/versions/1/PetImages/Dog\""
      ],
      "metadata": {
        "id": "LfghjPsAOwDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros gerais\n",
        "img_size = (150, 150)  # Tamanho padrão das imagens\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "RzsnC6VSPO7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento de imagem: redimensionamento e normalização\n",
        "def load_images_from_folder(folder, label, max_images=1000):\n",
        "    images = []\n",
        "    labels = []\n",
        "    count = 0\n",
        "    for filename in os.listdir(folder):\n",
        "        path = os.path.join(folder, filename)\n",
        "        try:\n",
        "            img = load_img(path, target_size=img_size)  # Redimensiona a imagem\n",
        "            img = img_to_array(img) / 255.0  # Converte para array e normaliza\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "            count += 1\n",
        "            if count >= max_images:\n",
        "                break\n",
        "        except:\n",
        "            continue  # Ignora imagens corrompidas\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "e1kf21taPT_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando imagens de gatos (0) e cachorros (1)\n",
        "cat_images, cat_labels = load_images_from_folder(dir_cat, 0)\n",
        "dog_images, dog_labels = load_images_from_folder(dir_dog, 1)\n",
        "\n",
        "print(f'Gatos: {len(cat_images)} imagens carregadas.')\n",
        "print(f'Cachorros: {len(dog_images)} imagens carregadas.')"
      ],
      "metadata": {
        "id": "tIYZiFGWPYmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separando os Dados de Treino, Validação e Teste"
      ],
      "metadata": {
        "id": "FrXACGWaQUvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unindo e embaralhando\n",
        "X = np.array(cat_images + dog_images)\n",
        "y = np.array(cat_labels + dog_labels)\n",
        "\n",
        "print(f'Total de imagens: {len(X)}')\n",
        "print(f'Total de rótulos: {len(y)}')"
      ],
      "metadata": {
        "id": "cLRIA2ePQLS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão: treino (70%), validação (15%), teste (15%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(f'Total de imagens: {len(X)}')\n",
        "print(f'Total de rótulos: {len(y)}')\n",
        "print(f'Treino: {len(X_train)} | Validação: {len(X_val)} | Teste: {len(X_test)}')"
      ],
      "metadata": {
        "id": "2INQJzSoQXV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Aumento de dados (data augmentation)"
      ],
      "metadata": {
        "id": "Stl8yXrjTULO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aumento de dados (data augmentation) para o treino\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "print(\"Data augmentation configurado para o conjunto de treino.\")"
      ],
      "metadata": {
        "id": "ZK3-72ZATX6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção e Treinamento do Modelo CNN"
      ],
      "metadata": {
        "id": "8fvf83KjTiN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitetura da CNN\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(150, 150, 3)),  # Adicione esta linha\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "print(\"Modelo CNN construído com sucesso.\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "F91narnETkUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilação do modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Modelo compilado com sucesso.\")"
      ],
      "metadata": {
        "id": "ORFkNkkiTom1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    batch_size=batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "print(\"Modelo treinado com sucesso.\")"
      ],
      "metadata": {
        "id": "niXBVuJhT2v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação e Testes"
      ],
      "metadata": {
        "id": "vqHRDesIUB3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliando os Resultados"
      ],
      "metadata": {
        "id": "hve7cOIJVuwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráficos de acurácia e perda\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Acurácia Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia Validação')\n",
        "plt.title('Acurácia por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Perda Treino')\n",
        "plt.plot(history.history['val_loss'], label='Perda Validação')\n",
        "plt.title('Perda por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pVQn8SLlUCuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação no Conjunto de Teste\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator)\n",
        "y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "y_true = y_test\n",
        "\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Cat\", \"Dog\"]))\n",
        "\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(\"\\nAcurácia no conjunto de teste:\", np.mean(y_pred == y_true))\n",
        "print(\"Acurácia no conjunto de teste:\", model.evaluate(test_generator)[1])"
      ],
      "metadata": {
        "id": "853w8vurUPey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando com Imagens Diferentes"
      ],
      "metadata": {
        "id": "jHqJ1JaNV0uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para testar imagem externa\n",
        "def testar_imagem(path):\n",
        "    imagem = load_img(path, target_size=img_size)\n",
        "    imagem_array = img_to_array(imagem) / 255.0\n",
        "    imagem_array = np.expand_dims(imagem_array, axis=0)\n",
        "    pred = model.predict(imagem_array)[0][0]\n",
        "    classe = \"Dog\" if pred > 0.5 else \"Cat\"\n",
        "    print(f\"Imagem: {os.path.basename(path)} | Classificação: {classe} ({pred:.2f})\")"
      ],
      "metadata": {
        "id": "oEBIO9jcV5T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTestando imagens externas:\")\n",
        "testar_imagem(\"/kaggle/input/microsoft-catsvsdogs-dataset/versions/1/PetImages/Cat/2001.jpg\")\n",
        "testar_imagem(\"/kaggle/input/microsoft-catsvsdogs-dataset/versions/1/PetImages/Dog/2001.jpg\")\n",
        "testar_imagem(\"/kaggle/input/microsoft-catsvsdogs-dataset/versions/1/PetImages/Cat/2002.jpg\")\n",
        "testar_imagem(\"/kaggle/input/microsoft-catsvsdogs-dataset/versions/1/PetImages/Dog/2002.jpg\")"
      ],
      "metadata": {
        "id": "puiuZRE2V9bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão"
      ],
      "metadata": {
        "id": "2gJJvOueWTcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A rede neural convolucional implementada foi capaz de aprender padrões visuais relevantes e realizar a classificação de forma eficaz. A combinação de pré-processamento, aumento de dados e arquitetura convolucional permitiu um desempenho robusto, mesmo com uma base de dados relativamente simples. Além disso, como a CNN foi treinada com uma quantidade relativamente baixa de instâncias, os resultados obtidos foram abaixo do esperado. Entretando, ao aumentar a quantidade de imagens para próximo de 5.000 imagens de cada classe, a acurácia ficou próxima dos 78%, indicando que a quantidade de imagens é extremamente relevante para a melhora ou piora do modelo."
      ],
      "metadata": {
        "id": "jSjaqWBdWWRc"
      }
    }
  ]
}